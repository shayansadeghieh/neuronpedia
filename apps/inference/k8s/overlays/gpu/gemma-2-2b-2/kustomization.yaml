resources:
  - ../base-lite
namePrefix: gemma-2-2b-2-
commonLabels:
  instance: gemma-2-2b-2
configMapGenerator:
  - name: inference-config
    literals:
      - MODEL_ID=gemma-2-2b
      - OVERRIDE_MODEL_ID=gemma-2-2b
      - DEVICE=cuda
      - MODEL_DTYPE=bfloat16
      - SAE_DTYPE=float16
      - TOKEN_LIMIT=400
      - HOST=0.0.0.0
      - PORT=5002
      - MAX_LOADED_SAES=500
      - SAE_SETS=["gemmascope-mlp-16k", "gemmascope-transcoder-16k"]
